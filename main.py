# 1. Import
from influxdb import InfluxDBClient
import streamlit as st
from collections import Counter
from datetime import datetime, time, timedelta
import pandas as pd
import io
import numpy as np
import processDataset
import zipfile
from dotenv import load_dotenv
import os
import pytz

# Load environment variables from .env file
load_dotenv()

# InfluxDB connection settings
host = os.getenv("INFLUXDB_HOST") or "localhost"
port_str = os.getenv("INFLUXDB_PORT")
port = int(port_str) if port_str is not None else 8086  # Default to 8086 if not set
username = os.getenv("INFLUXDB_USER") or ""
password = os.getenv("INFLUXDB_PASS") or ""
database = os.getenv("INFLUXDB_DB") or ""

# Create InfluxDB client
client = InfluxDBClient(
    host=host,
    port=port,
    username=username,
    password=password,
    database=database
)

#---------------------------------------------------------------------------------------

# 2. Functions
def connect_influxdb_v1():
    try:
        client = InfluxDBClient(
            host=os.getenv("INFLUXDB_HOST") or "",
            port=int(os.getenv("INFLUXDB_PORT") or 8086),
            username=os.getenv("INFLUXDB_USER") or "",
            password=os.getenv("INFLUXDB_PASS") or "",
            database=os.getenv("INFLUXDB_DB") or ""
        )
        client.get_list_database()
        print("[DEBUG] Connected to InfluxDB successfully.")
        return client
    except Exception as e:
        print(f"[ERROR] Failed to connect to InfluxDB: {e}")
        return None

def get_measurements(client):
    try:
        result = client.query("SHOW MEASUREMENTS")
        measurements = [m['name'] for m in result.get_points()]
        return measurements
    except Exception as e:
        print(f"[ERROR] Failed to query measurements: {e}")
        return []

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á Serial No. ‡∏à‡∏≤‡∏Å measurement ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
def get_serial_numbers(client, measurement):
    try:
        # ‡πÉ‡∏ä‡πâ SHOW TAG VALUES ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Grafana ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á serial number ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        query = f'SHOW TAG VALUES FROM "{measurement}" WITH KEY = "sn"'
        result = client.query(query)
        serials = [point['value'] for point in result.get_points()]
        return serials
    except Exception as e:
        print(f"[ERROR] Failed to query serial numbers: {e}")
        return []

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á Station Names (sName) ‡∏à‡∏≤‡∏Å measurement
def get_station_names(client, measurement):
    try:
        query = f'SHOW TAG VALUES FROM "{measurement}" WITH KEY = "sName"'
        result = client.query(query)
        stations = [point['value'] for point in result.get_points()]
        return stations
    except Exception as e:
        print(f"[ERROR] Failed to query station names: {e}")
        return []

#---------------------------------------------------------------------------------------

# 3. UI


client = connect_influxdb_v1()
if client:
    measurements = get_measurements(client)
else:
    measurements = []


st.title("Smell Model Mini-App")

# --- Date & Time Picker ---
col1, col2 = st.columns(2)
with col1:
    start_date = st.date_input("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô", value=datetime.now().date() - timedelta(days=1))
    start_time = st.time_input("‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô", value=time(0, 0))
with col2:
    end_date = st.date_input("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î", value=datetime.now().date())
    end_time = st.time_input("‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î", value=time(23, 59))

# ‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏õ‡πá‡∏ô datetime (‡πÉ‡∏ä‡πâ Bangkok timezone)
bangkok_tz = pytz.timezone('Asia/Bangkok')
start_dt = bangkok_tz.localize(datetime.combine(start_date, start_time))
end_dt = bangkok_tz.localize(datetime.combine(end_date, end_time))

# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô unix timestamp (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ) - ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô UTC timestamp
start_unix = int(start_dt.timestamp())
end_unix = int(end_dt.timestamp())

st.write(f"Unix timestamp ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô : {start_unix}")
st.write(f"Unix timestamp ‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î : {end_unix}")

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô sort serial number
def serial_sort_key(sn):
    try:
        parts = sn.split('-')
        if len(parts) >= 3:
            month = int(parts[1][:2])
            year = int(parts[1][2:])
            return (year, month, sn)
    except Exception:
        pass
    return (0, 0, sn)

if not measurements:
    measurements = ["-"]
    selected_measurement = st.selectbox("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Measurement :", measurements, index=0)
    serial_numbers = []
    unique_serial_numbers = ["-"]
    selected_sn = st.selectbox("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Serial No. :", unique_serial_numbers, disabled=True)
    selected_station = None
else:
    measurements = ["-"] + measurements
    selected_measurement = st.selectbox("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Measurement :", measurements, index=0)
    serial_numbers = []
    if client and selected_measurement != "-":
        serial_numbers = get_serial_numbers(client, selected_measurement)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å "‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠" ‡∏•‡∏á‡πÉ‡∏ô dropdown
    unique_serial_numbers = sorted(set(serial_numbers), key=serial_sort_key) if serial_numbers else []
    if unique_serial_numbers:
        unique_serial_numbers = ["-"] + unique_serial_numbers + ["‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å Station"]
    else:
        unique_serial_numbers = ["-", "‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å Station"]
    
    selected_sn = st.selectbox("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Serial No. :", unique_serial_numbers)
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å "‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠" ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á dropdown Station
    selected_station = None
    if selected_sn == "‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å Station":
        if client and selected_measurement != "-":
            station_names = get_station_names(client, selected_measurement)
            unique_stations = sorted(set(station_names)) if station_names else ["-"]
            if unique_stations and unique_stations != ["-"]:
                unique_stations = ["-"] + unique_stations
            selected_station = st.selectbox("üîç ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Station (sName) :", unique_stations)
            if selected_station != "-":
                st.info(f"üí° ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÉ‡∏ä‡πâ Station: **{selected_station}** ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ query ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                # ‡πÉ‡∏ä‡πâ selected_station ‡πÄ‡∏õ‡πá‡∏ô serial number ‡πÅ‡∏ó‡∏ô
                selected_sn = selected_station
        else:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Measurement ‡∏Å‡πà‡∏≠‡∏ô")
            selected_sn = "-"

st.write(f"Measurement ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å : {selected_measurement}")
if selected_station:
    st.write(f"üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å Station : {selected_station}")
else:
    st.write(f"Serial No. ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å : {selected_sn}")

if 'csv_files' not in st.session_state:
    st.session_state.csv_files = {}

# Initialize session state for splits
if 'splits' not in st.session_state:
    st.session_state.splits = []
if 'num_splits' not in st.session_state:
    st.session_state.num_splits = 1
if 'show_split_config' not in st.session_state:
    st.session_state.show_split_config = False

def build_query(measurement, serial_no, start_unix, end_unix, use_station=False):
    # InfluxDB ‡πÉ‡∏ä‡πâ ms
    # ‡∏ñ‡πâ‡∏≤ use_station=True ‡∏à‡∏∞‡πÉ‡∏ä‡πâ sName ‡πÅ‡∏ó‡∏ô sn ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ query
    tag_key = "sName" if use_station else "sn"
    query = f'''
    SELECT mean("a1") AS "s1", mean("a2") AS "s2", mean("a3") AS "s3", mean("a4") AS "s4",
           mean("a5") AS "s5", mean("a6") AS "s6", mean("a7") AS "s7", mean("a8") AS "s8"
    FROM "{measurement}"
    WHERE ("{tag_key}" =~ /^({serial_no})$/)
      AND time >= {start_unix}000ms AND time <= {end_unix}000ms
    GROUP BY time(1m) fill(none)
    '''
    return query

def query_to_dataframe(client, query):
    try:
        result = client.query(query)
        # get_points ‡∏≠‡∏≤‡∏à error ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ series
        points = []
        for serie in result.raw.get('series', []):
            for v in serie.get('values', []):
                # Map columns to values
                row = dict(zip(serie['columns'], v))
                points.append(row)
        if not points:
            return pd.DataFrame(columns=["Time", "s1", "s2", "s3", "s4", "s5", "s6", "s7", "s8", "Smell"])
        df = pd.DataFrame(points)
        # Rename time column
        df.rename(columns={"time": "Time"}, inplace=True)
        # Convert time - InfluxDB returns UTC time, convert to Bangkok timezone properly
        df["Time"] = pd.to_datetime(df["Time"], utc=True).dt.tz_convert('Asia/Bangkok').dt.strftime('%d/%m/%Y  %H:%M:%S')
        # Only keep s1-s8
        for col in ["s1","s2","s3","s4","s5","s6","s7","s8"]:
            if col in df.columns:
                df[col] = df[col].round().astype('Int64').astype(str).replace('<NA>', '')
            else:
                df[col] = ''
        # Add Smell column
        df["Smell"] = ""
        # Reorder columns
        df = df[["Time", "s1", "s2", "s3", "s4", "s5", "s6", "s7", "s8", "Smell"]]
        return df
    except Exception as e:
        st.error(f"[ERROR] Query failed: {e}")
        return pd.DataFrame(columns=["Time", "s1", "s2", "s3", "s4", "s5", "s6", "s7", "s8", "Smell"])

if serial_numbers:
    sn_counter = Counter(serial_numbers)
    duplicate_count = sum(1 for v in sn_counter.values() if v > 1)
    unique_count = len(sn_counter)
    # ‡∏ô‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ serial number ‡∏à‡∏£‡∏¥‡∏á (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° "-" ‡πÅ‡∏•‡∏∞ "‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠...")
    actual_sn_count = len([sn for sn in unique_serial_numbers if sn != "-" and not sn.startswith("‚ùå")])
    st.write(f"Serial No. ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô dropdown : {actual_sn_count} ‡∏ï‡∏±‡∏ß | ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ Query ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î : {len(serial_numbers)} ‡∏ï‡∏±‡∏ß | ‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥ : {unique_count} ‡∏ï‡∏±‡∏ß | ‡∏ã‡πâ‡∏≥ : {duplicate_count} ‡∏ï‡∏±‡∏ß")
else:
    st.write("Serial No. ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô dropdown : 0 ‡∏ï‡∏±‡∏ß | ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ Query ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î : 0 ‡∏ï‡∏±‡∏ß | ‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥ : 0 ‡∏ï‡∏±‡∏ß | ‡∏ã‡πâ‡∏≥ : 0 ‡∏ï‡∏±‡∏ß")

st.markdown("")

# ‡∏õ‡∏∏‡πà‡∏° Export to CSV
if st.button("Export to CSV", type="primary"):
    # Validation ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß
    if not selected_measurement or selected_measurement == "-":
        st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Measurement ‡∏Å‡πà‡∏≠‡∏ô export")
    elif not selected_sn or selected_sn == "-" or selected_sn == "‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å Station":
        st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Serial No. ‡∏´‡∏£‡∏∑‡∏≠ Station ‡∏Å‡πà‡∏≠‡∏ô export")
    else:
        st.session_state.show_split_config = True
        st.session_state.selected_measurement = selected_measurement
        st.session_state.selected_sn = selected_sn
        st.session_state.use_station = (selected_station is not None)
        st.rerun()

# ‡πÅ‡∏™‡∏î‡∏á‡∏™‡πà‡∏ß‡∏ô Split Configuration
if st.session_state.get('show_split_config', False):
    st.markdown("---")
    st.subheader("‚öôÔ∏è ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Time Range Splits")
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô splits
    num_splits = st.number_input("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Split ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:", min_value=1, max_value=20, value=st.session_state.num_splits, step=1)
    st.session_state.num_splits = num_splits
    
    # Initialize splits list if needed
    if len(st.session_state.splits) != num_splits:
        st.session_state.splits = [
            {
                'start_date': start_date,
                'start_time': start_time,
                'end_date': end_date,
                'end_time': end_time,
                'smell_label': f'Smell {i+1}',
                'smell_name': ''
            } for i in range(num_splits)
        ]
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ split
    for i in range(num_splits):
        with st.expander(f"üìã Split {i+1}", expanded=(i==0)):
            col1, col2 = st.columns(2)
            with col1:
                split_start_date = st.date_input(
                    f"‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (Split {i+1})",
                    value=st.session_state.splits[i]['start_date'],
                    min_value=start_date,
                    max_value=end_date,
                    key=f"split_{i}_start_date"
                )
                split_start_time = st.time_input(
                    f"‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (Split {i+1})",
                    value=st.session_state.splits[i]['start_time'],
                    key=f"split_{i}_start_time"
                )
            with col2:
                split_end_date = st.date_input(
                    f"‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î (Split {i+1})",
                    value=st.session_state.splits[i]['end_date'],
                    min_value=start_date,
                    max_value=end_date,
                    key=f"split_{i}_end_date"
                )
                split_end_time = st.time_input(
                    f"‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î (Split {i+1})",
                    value=st.session_state.splits[i]['end_time'],
                    key=f"split_{i}_end_time"
                )
            
            col3, col4 = st.columns(2)
            with col3:
                smell_label = st.text_input(
                    f"Smell Label (Split {i+1})",
                    value=st.session_state.splits[i]['smell_label'],
                    key=f"split_{i}_smell_label",
                )
            with col4:
                smell_name = st.text_input(
                    f"‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏¥‡πà‡∏ô (Split {i+1})",
                    value=st.session_state.splits[i]['smell_name'],
                    key=f"split_{i}_smell_name",
                )
            
            # Update session state
            st.session_state.splits[i] = {
                'start_date': split_start_date,
                'start_time': split_start_time,
                'end_date': split_end_date,
                'end_time': split_end_time,
                'smell_label': smell_label,
                'smell_name': smell_name
            }
    
    st.markdown("")
    
    # ‡∏õ‡∏∏‡πà‡∏° Process All Splits
    if st.button("‚úÖ Process All Splits", type="primary"):
        # Validate all splits
        validation_errors = []
        for i, split in enumerate(st.session_state.splits):
            # Check if smell_name is filled
            if not split['smell_name'] or split['smell_name'].strip() == '':
                validation_errors.append(f"‚ùå Split {i+1}: ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏¥‡πà‡∏ô")
            
            # Check if time range is within main time range
            split_start_dt = datetime.combine(split['start_date'], split['start_time'])
            split_end_dt = datetime.combine(split['end_date'], split['end_time'])
            main_start_dt = datetime.combine(start_date, start_time)
            main_end_dt = datetime.combine(end_date, end_time)
            
            if split_start_dt < main_start_dt:
                validation_errors.append(f"‚ùå Split {i+1}: ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ {start_time.strftime('%H:%M')}")
            if split_end_dt > main_end_dt:
                validation_errors.append(f"‚ùå Split {i+1}: ‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô {end_time.strftime('%H:%M')}")
            if split_start_dt >= split_end_dt:
                validation_errors.append(f"‚ùå Split {i+1}: ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î")
        
        # Show validation errors
        if validation_errors:
            for error in validation_errors:
                st.error(error)
        else:
            # Process if validation passes
            all_dfs = []
            smell_name_mapping = {}
            
            # Process each split
            for i, split in enumerate(st.session_state.splits):
                # Convert to datetime
                split_start_dt = bangkok_tz.localize(datetime.combine(split['start_date'], split['start_time']))
                split_end_dt = bangkok_tz.localize(datetime.combine(split['end_date'], split['end_time']))
                split_start_unix = int(split_start_dt.timestamp())
                split_end_unix = int(split_end_dt.timestamp())
                
                # Query data
                use_station = st.session_state.get('use_station', False)
                query = build_query(st.session_state.selected_measurement, st.session_state.selected_sn, split_start_unix, split_end_unix, use_station)
                df = query_to_dataframe(client, query)
                
                if not df.empty:
                    # Set Smell label for entire split
                    df['Smell'] = split['smell_label']
                    all_dfs.append(df)
                    
                    # Store smell name mapping
                    smell_name_mapping[split['smell_label']] = split['smell_name']
            
            # Concatenate all dataframes (‡∏£‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å loop ‡πÄ‡∏™‡∏£‡πá‡∏à)
            if all_dfs:
                combined_df = pd.concat(all_dfs, ignore_index=True)
                
                # Save to session state
                csv_buffer = io.StringIO()
                combined_df.to_csv(csv_buffer, index=False, encoding="utf-8-sig")
                st.session_state.csv_files["smell_label.csv"] = csv_buffer.getvalue()
                
                # Create smell name mapping Excel
                name_df = pd.DataFrame([
                    {'Smell': k, 'Name': v} for k, v in smell_name_mapping.items()
                ])
                excel_buffer = io.BytesIO()
                name_df.to_excel(excel_buffer, index=False)
                st.session_state.csv_files["smell_Name.xlsx"] = excel_buffer.getvalue()
                
                st.success(f"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(all_dfs)} splits ({len(combined_df)} ‡πÅ‡∏ñ‡∏ß)")
                
                # Show final combined table only
                st.markdown("#### üëÄ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡πÅ‡∏•‡πâ‡∏ß (Final)")
                st.dataframe(combined_df, use_container_width=True)
                
                st.markdown("#### üìù Smell Name Mapping")
                st.dataframe(name_df, use_container_width=True)
            else:
                st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")

# ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Memory
if st.session_state.csv_files:
    st.markdown("---")
    st.subheader("üíæ ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Memory")
    with st.expander(f"üìÅ ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ({len(st.session_state.csv_files)} ‡πÑ‡∏ü‡∏•‡πå)", expanded=False):
        for filename, content in st.session_state.csv_files.items():
            st.markdown(f"üìÑ **{filename}** ({len(content)} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)")
    if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô Memory", type="secondary"):
        st.session_state.csv_files = {}
        st.session_state.pop('show_smell_name_editor', None)
        st.session_state.pop('edit_df', None)
        st.session_state.pop('edit_filename', None)
        st.session_state.pop('show_split_config', None)
        st.session_state.pop('use_station', None)
        st.session_state.pop('selected_measurement', None)
        st.session_state.pop('selected_sn', None)
        st.session_state.splits = []
        st.success("‚úÖ ‡∏•‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Memory ‡πÅ‡∏•‡πâ‡∏ß")
        st.rerun()

# --- Plot Model ---
if "smell_label.csv" in st.session_state.csv_files and "smell_Name.xlsx" in st.session_state.csv_files:
    st.markdown("---")
    st.subheader("üî¨ Plot Model (‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)")
    if st.button("Plot Model", type="primary"):
        outputs = processDataset.process_smell_label(
            st.session_state.csv_files["smell_label.csv"],
            io.BytesIO(st.session_state.csv_files["smell_Name.xlsx"])
        )

        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á CSV
        st.markdown("#### sorted_labeled_data.csv")
        st.dataframe(pd.read_csv(io.StringIO(outputs["sorted_labeled_data.csv"])))
        st.markdown("#### dataset.csv")
        st.dataframe(pd.read_csv(io.StringIO(outputs["dataset.csv"])))
        st.markdown("#### average_smell_sensor_values.csv")
        st.dataframe(pd.read_csv(io.StringIO(outputs["average_smell_sensor_values.csv"])))

        # ‡πÅ‡∏™‡∏î‡∏á radar chart
        st.markdown("#### Radar Chart (PNG)")
        radar_files = [k for k in outputs if k.startswith("radarPlot/") and k.endswith(".png")]
        for fname in sorted(radar_files):
            st.image(outputs[fname], caption=fname, use_container_width=True)

        # ‡πÅ‡∏™‡∏î‡∏á PCA plot
        st.markdown("#### PCA Analysis (2D Scatter Plot)")
        pca_files = [k for k in outputs if k.startswith("pcaPlot/") and k.endswith(".png")]
        for fname in sorted(pca_files):
            st.image(outputs[fname], caption=fname, use_container_width=True)

        # ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î zip
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, "w") as zf:
            for fname, content in outputs.items():
                zf.writestr(fname, content if isinstance(content, bytes) else content.encode("utf-8"))
        st.download_button("Download All Output (ZIP)", data=zip_buffer.getvalue(), file_name="smell_model_outputs.zip")

# ‡∏Å‡∏±‡∏ô SQL Injection
if selected_measurement not in measurements:
    st.error("Measurement ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    st.stop()

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Serial No. ‡∏´‡∏£‡∏∑‡∏≠ Station
if selected_station:
    # ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ Station ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤ station ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if client and selected_measurement != "-":
        valid_stations = get_station_names(client, selected_measurement)
        if selected_station not in valid_stations:
            st.error("Station ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
            st.stop()
else:
    # ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ Serial No. ‡∏ï‡∏£‡∏ß‡∏à‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏¥‡∏°
    if selected_sn not in unique_serial_numbers:
        st.error("Serial No. ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
        st.stop()






